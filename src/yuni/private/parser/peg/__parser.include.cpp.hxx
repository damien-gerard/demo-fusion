
template<class StreamT>
static inline void PrepareCPPInclude(StreamT& out)
{
	out << "	//! Add traces to the stdcout\n";
	out << "	# define HAS_TRACES 0\n";
	out << '\n';
	out << "	# define HAS_STATISTICS 0\n";
	out << '\n';
	out << "	//! Size (in bytes), when increasing the stack capacity\n";
	out << "	# define GROW_CHUNK  1024 // 1024 * sizeof(Chunk) -> 16KiB\n";
	out << '\n';
	out << "	//! Arbitrary value for consistency checks\n";
	out << "	# define ARBITRARY_HARD_LIMIT  (1024 * 1024 * 500)\n";
	out << '\n';
	out << '\n';
	out << "	# ifndef NDEBUG\n";
	out << "	# define TRACE_INFO(X)  std::cout << \"  == parser == \" << X << std::endl\n";
	out << "	# else\n";
	out << "	# define TRACE_INFO(X)  {}\n";
	out << "	# endif\n";
	out << '\n';
	out << '\n';
	out << "	# if HAS_TRACES != 0\n";
	out << '\n';
	out << "	# define TRACE(X) \\\n";
	out << "		do { \\\n";
	out << "			assert(ctx.offset < ctx.capacity); /* valid only because not called from grow */ \\\n";
	out << "			assert(ctx.stack[ctx.offset].urlindex < (uint) ctx.urls.size()); \\\n";
	out << "			const String& filename = ctx.urls[ctx.stack[ctx.offset].urlindex]; \\\n";
	out << "			assert(filename.size() < 65535); \\\n";
	out << "			assert(filename.capacity() < 65535); \\\n";
	out << "			assert(filename.data() != NULL); \\\n";
	out << "			\\\n";
	out << "			std::cout << \"  == parser == stack == \" << filename \\\n";
	out << "				<< \", depth:\" << ctx.offset << \": \" << X << std::endl; \\\n";
	out << "		} while (false)\n";
	out << '\n';
	out << '\n';
	out << "	# define TRACE_LOCAL(X) \\\n";
	out << "		do { \\\n";
	out << "			assert(stack[offset].urlindex < (uint) urls.size()); \\\n";
	out << "			const String& filename = urls[stack[offset].urlindex]; \\\n";
	out << "			assert(filename.size() < 65535); \\\n";
	out << "			assert(filename.capacity() < 65535); \\\n";
	out << "			assert(filename.data() != NULL); \\\n";
	out << "			\\\n";
	out << "			std::cout << \"  == parser == stack == \" << filename \\\n";
	out << "				<< \", depth:\" << offset << \": \" << X << std::endl; \\\n";
	out << "		} while (false)\n";
	out << '\n';
	out << "	# else\n";
	out << '\n';
	out << "	# define TRACE(X)  {}\n";
	out << '\n';
	out << "	# define TRACE_LOCAL(X)  {}\n";
	out << '\n';
	out << "	# endif\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << '\n';
	out << "	# define DATASOURCE_PARSE(ctx) \\\n";
	out << "		do { \\\n";
	out << "			sint64 start = ::Yuni::DateTime::NowMilliSeconds(); \\\n";
	out << "			ctx.clear(); \\\n";
	out << "			ctx.success = yyrgStart(ctx) and ctx.isParseComplete(); \\\n";
	out << "			ctx.duration = (uint64) (::Yuni::DateTime::NowMilliSeconds() - start); \\\n";
	out << "			ctx.buildAST(); \\\n";
	out << "			root = ctx.rootnode; \\\n";
	out << "		} \\\n";
	out << "		while (false)\n";
	out << '\n';
	out << "	# else\n";
	out << '\n';
	out << "	# define DATASOURCE_PARSE(ctx) \\\n";
	out << "		do { \\\n";
	out << "			ctx.clear(); \\\n";
	out << "			ctx.success = yyrgStart(ctx) and ctx.isParseComplete(); \\\n";
	out << "			ctx.buildAST(); \\\n";
	out << "			root = ctx.rootnode; \\\n";
	out << "		} \\\n";
	out << "		while (false)\n";
	out << '\n';
	out << "	# endif // HAS_STATISTICS\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	struct Chunk\n";
	out << "	{\n";
	out << "		//! Rule ID - a negative value means that the rule has not been commited yet\n";
	out << "		int rule;\n";
	out << "		//! Iterator on the source\n";
	out << "		uint offset;\n";
	out << "		//! Index of the current source url (see `urls`)\n";
	out << "		uint urlindex;\n";
	out << "		//! End offset - means nothing if rule == 0\n";
	out << "		uint offsetEnd;\n";
	out << "		//! Parent rule\n";
	out << "		uint parent;\n";
	out << "	};\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	class Datasource final\n";
	out << "	{\n";
	out << "	public:\n";
	out << '\n';
	out << "	public:\n";
	out << "		//! \\name Constructors\n";
	out << "		//@{\n";
	out << "		//! Default constructor\n";
	out << "		Datasource(Notification::Vector& notifications);\n";
	out << "		~Datasource();\n";
	out << "		//@}\n";
	out << '\n';
	out << "		//! \\name Matching\n";
	out << "		//@{\n";
	out << "		bool matchSingleAsciiChar(char);\n";
	out << "		bool matchString(const AnyString& text);\n";
	out << "		bool matchOneOf(const AnyString& text);\n";
	out << '\n';
	out << "		bool notMatchSingleAsciiChar(char);\n";
	out << "		bool notMatchOneOf(const AnyString& text);\n";
	out << "		//@}\n";
	out << '\n';
	out << "		//! \\name Chunk\n";
	out << "		//@{\n";
	out << "		void pushInclude(uint urlindex);\n";
	out << "		uint push();\n";
	out << "		uint enterRule(enum Rule rule);\n";
	out << "		void restart(uint from);\n";
	out << "		void commit(uint ruleOffset, enum Rule rule);\n";
	out << "		//@}\n";
	out << '\n';
	out << "		//! \\name Filename manipulation\n";
	out << "		//@{\n";
	out << "		//! Open a new url\n";
	out << "		bool open(const AnyString& newurl);\n";
	out << "		//! Open from anonymous origin\n";
	out << "		void openContent(const AnyString& content);\n";
	out << "		//! Close the current url\n";
	out << "		void close();\n";
	out << "		//@}\n";
	out << '\n';
	out << "		//! \\name AST Builder\n";
	out << "		//@{\n";
	out << "		//! Clear internal variables\n";
	out << "		void clear();\n";
	out << "		//! Build the whole AST from the stack informations\n";
	out << "		void buildAST();\n";
	out << '\n';
	out << "		//! Get if the parse has been successful or not\n";
	out << "		bool isParseComplete() const;\n";
	out << "		//@}\n";
	out << '\n';
	out << '\n';
	out << "		//! \\name Notifications\n";
	out << "		//@{\n";
	out << "		//! Create a new notification\n";
	out << "		void notify(const AnyString& message) const;\n";
	out << "		//@}\n";
	out << '\n';
	out << '\n';
	out << "		//! \\name Address translation\n";
	out << "		//@{\n";
	out << "		void translateOffset(uint& column, uint& line, uint offset) const;\n";
	out << "		//@}\n";
	out << '\n';
	out << '\n';
	out << "	public:\n";
	out << "		//! Stack\n";
	out << "		Chunk* stack;\n";
	out << "		uint offset;\n";
	out << "		# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << "		uint maxOffset;\n";
	out << "		uint64 duration;\n";
	out << "		# endif\n";
	out << "		uint capacity;\n";
	out << '\n';
	out << "		//! Root folder\n";
	out << "		YString root;\n";
	out << "		//! File Content of all encountered urls, ordered by their order of arrival\n";
	out << "		Clob::Vector contents;\n";
	out << "		//! Reverse mapping for retriving the index of a known file\n";
	out << "		::Yuni::Dictionary<String, uint>::Unordered  reverseUrlIndexes;\n";
	out << "		//! All urls\n";
	out << "		::Yuni::String::Vector urls;\n";
	out << '\n';
	out << "		//! Success flag\n";
	out << "		bool success;\n";
	out << "		//! Root node\n";
	out << "		Node::Ptr rootnode;\n";
	out << '\n';
	out << "		//! Notifications\n";
	out << "		Notification::Vector& notifications;\n";
	out << '\n';
	out << "	private:\n";
	out << "		void grow();\n";
	out << "		void buildASTForNonEmptyContent();\n";
	out << "		void findOptimalNewOffsetAfterCommit(uint ruleOffset);\n";
	out << '\n';
	out << "	}; // class Datasource\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	class OffsetAutoReset final\n";
	out << "	{\n";
	out << "	public:\n";
	out << "		OffsetAutoReset(Datasource& ctx) :\n";
	out << "			ctx(ctx),\n";
	out << "			oldOffset(ctx.offset),\n";
	out << "			oldFileOffset(ctx.stack[ctx.offset].offset)\n";
	out << "		{}\n";
	out << '\n';
	out << "		~OffsetAutoReset()\n";
	out << "		{\n";
	out << "			ctx.offset = oldOffset;\n";
	out << "			ctx.stack[oldOffset].offset = oldFileOffset;\n";
	out << "		}\n";
	out << '\n';
	out << "	private:\n";
	out << "		Datasource& ctx;\n";
	out << "		uint oldOffset;\n";
	out << "		uint oldFileOffset;\n";
	out << "	};\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	# ifndef NDEBUG\n";
	out << "	static inline std::ostream& PrintFrame(std::ostream& out, const Chunk& cursor)\n";
	out << "	{\n";
	out << "		out << \"{offset: \" << cursor.offset\n";
	out << "			<< \", url: \" << cursor.urlindex\n";
	out << "			<< \", rule: \" << cursor.rule\n";
	out << "			<< \", end: \" << cursor.offsetEnd\n";
	out << "			<< \", parent: \" << cursor.parent << \"}\";\n";
	out << "		return out;\n";
	out << "	}\n";
	out << "	# endif\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	inline Datasource::Datasource(Notification::Vector& notifications) :\n";
	out << "		stack(),\n";
	out << "		offset(),\n";
	out << "		capacity(GROW_CHUNK),\n";
	out << "		notifications(notifications)\n";
	out << "	{\n";
	out << "		stack = (Chunk*)::malloc(sizeof(Chunk) * GROW_CHUNK);\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline Datasource::~Datasource()\n";
	out << "	{\n";
	out << "		// rootnode = nullptr\n";
	out << "		::free(stack);\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::clear()\n";
	out << "	{\n";
	out << "		offset = 0;\n";
	out << "		success = false;\n";
	out << '\n';
	out << "		# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << "		maxOffset = 0;\n";
	out << "		duration  = 0;\n";
	out << "		# endif\n";
	out << '\n';
	out << "		rootnode = nullptr;\n";
	out << '\n';
	out << "		// avoid too much memory consumption\n";
	out << "		if (capacity > GROW_CHUNK * 1024)\n";
	out << "		{\n";
	out << "			capacity = GROW_CHUNK * 1024;\n";
	out << "			stack = (Chunk*)::realloc(stack, sizeof(Chunk) * capacity);\n";
	out << "		}\n";
	out << '\n';
	out << "		// initializing the first frame\n";
	out << "		Chunk& firstFrame = stack[0];\n";
	out << "		// no offset\n";
	out << "		firstFrame.offset = 0;\n";
	out << "		// the first one will be good enough\n";
	out << "		firstFrame.urlindex = 0;\n";
	out << "		// to make the frame 0 the root parent frame (and to avoid useless checks)\n";
	out << "		firstFrame.rule = - (int) rgEOF;\n";
	out << "		// no end\n";
	out << "		firstFrame.offsetEnd = 0;\n";
	out << "		// no parent\n";
	out << "		firstFrame.parent = 0;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::grow()\n";
	out << "	{\n";
	out << "		// WARNING The variable 'offset' might be unreliable for displying\n";
	out << "		// and/or checking values from the stack frames\n";
	out << "		assert(capacity + GROW_CHUNK < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << '\n';
	out << "		// grow the stack\n";
	out << "		stack = (Chunk*)::realloc(stack, (capacity += GROW_CHUNK) * sizeof(Chunk));\n";
	out << "		// post-checks\n";
	out << "		assert(offset < capacity);\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::pushInclude(uint urlindex)\n";
	out << "	{\n";
	out << "		assert(urlindex < ARBITRARY_HARD_LIMIT);\n";
	out << "		assert(capacity + GROW_CHUNK < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << "		assert(offset < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << "		assert(urls.size() == contents.size());\n";
	out << "		assert(urls.size() == reverseUrlIndexes.size());\n";
	out << '\n';
	out << "		if (YUNI_UNLIKELY(not (++offset < capacity))) // grow\n";
	out << "			grow();\n";
	out << '\n';
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		cursor.offset    = 0;\n";
	out << "		cursor.urlindex  = urlindex;\n";
	out << "		cursor.rule      = 0;\n";
	out << "		cursor.offsetEnd = 0;\n";
	out << "		cursor.parent    = (uint) -1;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline uint Datasource::push()\n";
	out << "	{\n";
	out << "		assert(capacity + GROW_CHUNK < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << "		assert(offset < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << '\n';
	out << "		if (YUNI_UNLIKELY(not (++offset < capacity))) // grow\n";
	out << "			grow();\n";
	out << '\n';
	out << "		assert(offset < capacity);\n";
	out << "		# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << "		if (offset > maxOffset)\n";
	out << "			maxOffset = offset;\n";
	out << "		# endif\n";
	out << '\n';
	out << "		Chunk& cursor      = stack[offset];\n";
	out << "		const Chunk& prev  = stack[offset - 1];\n";
	out << '\n';
	out << "		assert(prev.offset < ARBITRARY_HARD_LIMIT);\n";
	out << "		assert(prev.urlindex < ARBITRARY_HARD_LIMIT);\n";
	out << '\n';
	out << "		cursor.offset    = prev.offset;\n";
	out << "		cursor.urlindex  = prev.urlindex;\n";
	out << "		cursor.rule      = 0;\n";
	out << "		// cursor.offsetEnd = 0;  means nothing if rule == 0\n";
	out << '\n';
	out << "		// Since TRACE_LOCAL uses cursor.offset, this macro must be called after\n";
	out << "		// the previous initialization\n";
	out << "		TRACE_LOCAL(\"    push at offset \" << prev.offset);\n";
	out << "		return offset - 1;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline uint Datasource::enterRule(enum Rule rule)\n";
	out << "	{\n";
	out << "		assert(capacity + GROW_CHUNK < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << "		assert(offset < ARBITRARY_HARD_LIMIT); // arbitrary\n";
	out << "		assert((uint) rule < (uint) ruleCount);\n";
	out << '\n';
	out << "		// This method is quite similar to `push`\n";
	out << "		// Grow !\n";
	out << "		if (YUNI_UNLIKELY(not (++offset < capacity)))\n";
	out << "			grow();\n";
	out << '\n';
	out << "		# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << "		if (offset > maxOffset)\n";
	out << "			maxOffset = offset;\n";
	out << "		# endif\n";
	out << '\n';
	out << "		assert(offset > 0);\n";
	out << "		assert(capacity < ARBITRARY_HARD_LIMIT);\n";
	out << "		Chunk& cursor      = stack[offset];\n";
	out << "		const Chunk& prev  = stack[offset - 1];\n";
	out << '\n';
	out << "		cursor.offset    = prev.offset;\n";
	out << "		cursor.urlindex  = prev.urlindex;\n";
	out << "		cursor.rule      = - ((int) rule);\n";
	out << "		cursor.offsetEnd = cursor.offset; // store offset for reuse at commit\n";
	out << '\n';
	out << "		TRACE_LOCAL(\"    enter at offset \" << cursor.offset);\n";
	out << "		return offset;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::findOptimalNewOffsetAfterCommit(uint ruleOffset)\n";
	out << "	{\n";
	out << "		// trying to reduce the stack size by removing all stack frames which are\n";
	out << "		// not marked as a real rule this optimization can reduce by 3 the size of\n";
	out << "		// the stack and reduce by 4 the time required to parse some big input\n";
	out << '\n';
	out << "		// if a stack frame with the variable 'rule' not null (aka a stack frame\n";
	out << "		// dedicated to create a node in the AST), then it would not be safe to\n";
	out << "		// get rid of the end of the stack\n";
	out << "		for (uint i = ruleOffset + 1; i <= offset; ++i)\n";
	out << "		{\n";
	out << "			if (stack[i].rule != 0)\n";
	out << "			{\n";
	out << "				++offset;\n";
	out << "				return;\n";
	out << "			}\n";
	out << "		}\n";
	out << '\n';
	out << "		// it seems that it is safe to ignore the end of the stack - hourray \\o/\n";
	out << "		offset = ruleOffset + 1;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::commit(uint ruleOffset, enum Rule rule)\n";
	out << "	{\n";
	out << "		assert(stack[ruleOffset].rule == - (int) rule and \"inconsistency ruleid in the stack\");\n";
	out << "		assert(offset >= ruleOffset and \"invalid stack entre/commit\");\n";
	out << "		assert(stack[offset].offset >= stack[ruleOffset].offset and \"Huh? Should go forward...\");\n";
	out << "		(void) rule; // avoid warning in release mode\n";
	out << '\n';
	out << "		// committing the current stack frame\n";
	out << "		{\n";
	out << "			Chunk& ruleCursor = stack[ruleOffset];\n";
	out << '\n';
	out << "			// restore previous offset - a temporary variable must be used\n";
	out << "			// it may happen that `offset` and `ruleOffset` are the same\n";
	out << "			uint newEndOffset    = stack[offset].offset;\n";
	out << "			ruleCursor.offset    = ruleCursor.offsetEnd;\n";
	out << "			ruleCursor.offsetEnd = newEndOffset;\n";
	out << "			ruleCursor.rule      = (int) rule;\n";
	out << '\n';
	out << "			assert(ruleCursor.offset <= ruleCursor.offsetEnd and \"invalid boundaries\");\n";
	out << '\n';
	out << "			// Looking for the parent node\n";
	out << "			{\n";
	out << "				# ifndef NDEBUG\n";
	out << "				bool parentFound = false;\n";
	out << "				# endif\n";
	out << '\n';
	out << "				uint i = ruleOffset;\n";
	out << "				do\n";
	out << "				{\n";
	out << "					if (stack[--i].rule < 0)\n";
	out << "					{\n";
	out << "						ruleCursor.parent = i;\n";
	out << "						# ifndef NDEBUG\n";
	out << "						parentFound = true;\n";
	out << "						# endif\n";
	out << "						break;\n";
	out << "					}\n";
	out << "				}\n";
	out << "				while (i != 0);\n";
	out << '\n';
	out << "				# ifndef NDEBUG\n";
	out << "				if (not parentFound)\n";
	out << "				{\n";
	out << "					std::cerr << \"invalid parent commiting \" << ruleCursor.rule << \" at offset \" << ruleOffset << std::endl;\n";
	out << "					assert(false);\n";
	out << "				}\n";
	out << "				# endif\n";
	out << "			}\n";
	out << '\n';
	out << "			# if HAS_TRACES != 0\n";
	out << "			uint csize = ruleCursor.offsetEnd - ruleCursor.offset;\n";
	out << "			AnyString content(contents[ruleCursor.urlindex], ruleCursor.offset, csize);\n";
	out << "			TRACE_LOCAL(\"    COMMIT \" << RuleToString(rule) << \", offset \" << newEndOffset << \": \" << content);\n";
	out << "			# endif\n";
	out << "		}\n";
	out << '\n';
	out << "		// new stack frame - push - to keep this element in the stack\n";
	out << "		// calculating the new offset: [optimization]\n";
	out << "		findOptimalNewOffsetAfterCommit(ruleOffset);\n";
	out << '\n';
	out << "		if (YUNI_UNLIKELY(not (offset < capacity))) // grow !\n";
	out << "			grow();\n";
	out << '\n';
	out << "		# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << "		if (offset > maxOffset)\n";
	out << "			maxOffset = offset;\n";
	out << "		# endif\n";
	out << '\n';
	out << "		// the item at `ruleOffset` may have changed - re-acquiring a new ref on it\n";
	out << "		Chunk& ruleCursor = stack[ruleOffset];\n";
	out << "		Chunk& cursor     = stack[offset];\n";
	out << "		cursor.offset     = ruleCursor.offsetEnd;\n";
	out << "		cursor.urlindex   = ruleCursor.urlindex;\n";
	out << "		cursor.rule       = 0;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::restart(uint from)\n";
	out << "	{\n";
	out << "		// the method `push` returns `offset - 1`\n";
	out << "		assert(from + 1 < capacity);\n";
	out << "		assert(from < offset and \"can not restart from a non existing frame\");\n";
	out << '\n';
	out << "		offset = from + 1;\n";
	out << '\n';
	out << "		Chunk& cursor      = stack[offset];\n";
	out << "		const Chunk& prev  = stack[offset - 1];\n";
	out << '\n';
	out << "		cursor.offset    = prev.offset;\n";
	out << "		cursor.urlindex  = prev.urlindex;\n";
	out << "		cursor.rule      = 0;\n";
	out << "		TRACE_LOCAL(\"    restart at offset \" << cursor.offset);\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::open(const AnyString& newurl)\n";
	out << "	{\n";
	out << "		// getting the root directory once and for all if not already done\n";
	out << "		// the operation is not done in the constructor to let the caller\n";
	out << "		// initialize this variable if needed\n";
	out << "		if (root.empty())\n";
	out << "			::Yuni::IO::Directory::Current::Get(root, false);\n";
	out << '\n';
	out << "		// canonicalizing the filename\n";
	out << "		String filename;\n";
	out << "		::Yuni::IO::Canonicalize(filename, newurl, root);\n";
	out << '\n';
	out << "		// filename index\n";
	out << "		uint index;\n";
	out << "		Yuni::Dictionary<String, uint>::Unordered::const_iterator knownIndex = reverseUrlIndexes.find(filename);\n";
	out << "		if (YUNI_LIKELY(knownIndex == reverseUrlIndexes.end()))\n";
	out << "		{\n";
	out << "			assert(contents.size() == urls.size());\n";
	out << "			// indexes\n";
	out << "			index = (uint) contents.size();\n";
	out << "			reverseUrlIndexes[filename] = index;\n";
	out << "			// load the entire content in memory\n";
	out << "			contents.push_back(nullptr);\n";
	out << "			urls.push_back(filename);\n";
	out << "			if (::Yuni::IO::errNone != ::Yuni::IO::File::LoadFromFile(contents.back(), filename))\n";
	out << "				return false;\n";
	out << "		}\n";
	out << "		else\n";
	out << "			index = knownIndex->second;\n";
	out << '\n';
	out << "		// new item in the stack\n";
	out << "		pushInclude(index);\n";
	out << "		return true;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::openContent(const AnyString& content)\n";
	out << "	{\n";
	out << "		const String filename = \"<memory>\";\n";
	out << "		// filename index\n";
	out << "		uint index;\n";
	out << "		::Yuni::Dictionary<String, uint>::Unordered::const_iterator knownIndex = reverseUrlIndexes.find(filename);\n";
	out << "		if (YUNI_LIKELY(knownIndex == reverseUrlIndexes.end()))\n";
	out << "		{\n";
	out << "			assert(contents.size() == urls.size());\n";
	out << "			// indexes\n";
	out << "			index = (uint) contents.size();\n";
	out << "			reverseUrlIndexes[filename] = index;\n";
	out << "			urls.push_back(filename);\n";
	out << "			// load the entire content in memory\n";
	out << "			contents.push_back(nullptr);\n";
	out << "			contents.back() = content;\n";
	out << "		}\n";
	out << "		else\n";
	out << "			index = knownIndex->second;\n";
	out << '\n';
	out << "		pushInclude(index);\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::matchSingleAsciiChar(char c)\n";
	out << "	{\n";
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		const Clob& data = contents[cursor.urlindex];\n";
	out << "		if (cursor.offset < data.size() and c == data[cursor.offset])\n";
	out << "		{\n";
	out << "			++cursor.offset;\n";
	out << "			return true;\n";
	out << "		}\n";
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::matchString(const AnyString& text)\n";
	out << "	{\n";
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		const Clob& data = contents[cursor.urlindex];\n";
	out << '\n';
	out << "		if (AnyString(data, cursor.offset).startsWith(text))\n";
	out << "		{\n";
	out << "			cursor.offset += text.size();\n";
	out << "			return true;\n";
	out << "		}\n";
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::matchOneOf(const AnyString& text)\n";
	out << "	{\n";
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		const Clob& data = contents[cursor.urlindex];\n";
	out << '\n';
	out << "		if (cursor.offset < data.size())\n";
	out << "		{\n";
	out << "			if (text.contains(data[cursor.offset]))\n";
	out << "			{\n";
	out << "				++cursor.offset;\n";
	out << "				return true;\n";
	out << "			}\n";
	out << "		}\n";
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::notMatchSingleAsciiChar(char c)\n";
	out << "	{\n";
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		const Clob& data = contents[cursor.urlindex];\n";
	out << "		if (cursor.offset < data.size() and c != data[cursor.offset])\n";
	out << "		{\n";
	out << "			++cursor.offset;\n";
	out << "			return true;\n";
	out << "		}\n";
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::notMatchOneOf(const AnyString& text)\n";
	out << "	{\n";
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		const Clob& data = contents[cursor.urlindex];\n";
	out << '\n';
	out << "		if (cursor.offset < data.size())\n";
	out << "		{\n";
	out << "			if (not text.contains(data[cursor.offset]))\n";
	out << "			{\n";
	out << "				++cursor.offset;\n";
	out << "				return true;\n";
	out << "			}\n";
	out << "		}\n";
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	static bool StandardURILoaderHandler(Clob& out, const AnyString& uri)\n";
	out << "	{\n";
	out << "		if (not uri.empty())\n";
	out << "		{\n";
	out << "			out.clear();\n";
	out << "			if (::Yuni::IO::errNone == ::Yuni::IO::File::LoadFromFile(out, uri))\n";
	out << "				return true;\n";
	out << "		}\n";
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "	static void InternalNodeExportHTML(Clob& out, const Node& node, String& indent, String& tmp)\n";
	out << "	{\n";
	out << "		assert(&node != NULL);\n";
	out << "		out << indent << \"<div class=\\\"node\\\">\";\n";
	out << "		out << \"<span class=\\\"rule\\\">\" << RuleToString(node.rule) << \"</span>\";\n";
	out << '\n';
	out << "		bool attrCapture = RuleAttributeCapture(node.rule);\n";
	out << "		if (attrCapture)\n";
	out << "		{\n";
	out << "			// out << \" <span class=\\\"line\\\">l.\" << node.line << \"</span> \";\n";
	out << "			out << \" <code>\";\n";
	out << "			tmp = node.text;\n";
	out << "			tmp.replace(\"<\", \"&lt;\");\n";
	out << "			tmp.replace(\">\", \"&gt;\");\n";
	out << "			out << tmp << \"</code>\";\n";
	out << "		}\n";
	out << '\n';
	out << "		if (not node.children.empty())\n";
	out << "		{\n";
	out << "			out << '\\n' << indent << \"<ul>\\n\";\n";
	out << "			indent.append(\"    \", 4);\n";
	out << "			for (uint i = 0; i != (uint) node.children.size(); ++i)\n";
	out << "			{\n";
	out << "				out << indent << \"<li>\\n\";\n";
	out << "				InternalNodeExportHTML(out, *(node.children[i]), indent, tmp);\n";
	out << "				out << indent << \"</li>\\n\";\n";
	out << "			}\n";
	out << '\n';
	out << "			indent.chop(4);\n";
	out << "			out << indent << \"</ul>\\n\" << indent;\n";
	out << "		}\n";
	out << "		out << \"</div>\\n\";\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	template<bool ColorT>\n";
	out << "	static void InternalNodeExportConsole(Clob& out, const Node& node, bool hasSibling, String& indent, String& tmp)\n";
	out << "	{\n";
	out << "		using namespace ::Yuni::System::Console;\n";
	out << "		assert(&node != NULL);\n";
	out << '\n';
	out << "		if (ColorT)\n";
	out << "			::Yuni::System::Console::SetTextColor(out, blue);\n";
	out << "		out << indent;\n";
	out << '\n';
	out << "		if (not ColorT)\n";
	out << "		{\n";
	out << "			out << RuleToString(node.rule);\n";
	out << "		}\n";
	out << "		else\n";
	out << "		{\n";
	out << "			if (YUNI_UNLIKELY(RuleAttributeError(node.rule)))\n";
	out << "			{\n";
	out << "				::Yuni::System::Console::SetTextColor(out, red);\n";
	out << "				out << RuleToString(node.rule);\n";
	out << "				::Yuni::System::Console::ResetTextColor(out);\n";
	out << "			}\n";
	out << "			else\n";
	out << "			{\n";
	out << "				if (YUNI_UNLIKELY(RuleAttributeImportant(node.rule)))\n";
	out << "				{\n";
	out << "					::Yuni::System::Console::SetTextColor(out, purple);\n";
	out << "					out << RuleToString(node.rule);\n";
	out << "					::Yuni::System::Console::ResetTextColor(out);\n";
	out << "				}\n";
	out << "				else\n";
	out << "				{\n";
	out << "					::Yuni::System::Console::ResetTextColor(out);\n";
	out << "					out << RuleToString(node.rule);\n";
	out << "				}\n";
	out << "			}\n";
	out << "		}\n";
	out << '\n';
	out << "		bool attrCapture = RuleAttributeCapture(node.rule);\n";
	out << "		if (attrCapture)\n";
	out << "		{\n";
	out << "			tmp = node.text;\n";
	out << "			tmp.replace(\"\\n\", \"\\\\n\");\n";
	out << "			out << \": \";\n";
	out << '\n';
	out << "			if (ColorT)\n";
	out << "				::Yuni::System::Console::SetTextColor(out, green);\n";
	out << "			out << tmp;\n";
	out << "			if (ColorT)\n";
	out << "				::Yuni::System::Console::ResetTextColor(out);\n";
	out << "		}\n";
	out << "		else\n";
	out << "		{\n";
	out << "			// it can be interresting to print the text itself when the node\n";
	out << "			// is a simple text capture\n";
	out << "			AnyString textCapture = RuleAttributeSimpleTextCapture(node.rule);\n";
	out << "			if (not textCapture.empty())\n";
	out << "			{\n";
	out << "				out << \", \";\n";
	out << "				if (ColorT)\n";
	out << "					::Yuni::System::Console::SetTextColor(out, green);\n";
	out << "				out << textCapture;\n";
	out << "				if (ColorT)\n";
	out << "					::Yuni::System::Console::ResetTextColor(out);\n";
	out << "			}\n";
	out << "		}\n";
	out << '\n';
	out << "		if (node.children.size() > 1)\n";
	out << "		{\n";
	out << "			if (ColorT)\n";
	out << "				::Yuni::System::Console::SetTextColor(out, blue);\n";
	out << "			out << \" (+\" << node.children.size() << ')';\n";
	out << "		}\n";
	out << '\n';
	out << "		out << '\\n';\n";
	out << '\n';
	out << "		// sub nodes\n";
	out << "		if (not node.children.empty())\n";
	out << "		{\n";
	out << "			if (hasSibling)\n";
	out << "				indent.append(\"|   \", 4);\n";
	out << "			else\n";
	out << "				indent.append(\"    \", 4);\n";
	out << '\n';
	out << "			for (uint i = 0; i != (uint) node.children.size(); ++i)\n";
	out << "			{\n";
	out << "				bool hasSibling = (i != (uint) node.children.size() - 1);\n";
	out << "				InternalNodeExportConsole<ColorT>(out, *(node.children[i]), hasSibling, indent, tmp);\n";
	out << "			}\n";
	out << '\n';
	out << "			indent.chop(4);\n";
	out << "		}\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	void Datasource::buildAST()\n";
	out << "	{\n";
	out << "		if (success)\n";
	out << "		{\n";
	out << "			if (offset > 0) // not empty content\n";
	out << "			{\n";
	out << "				buildASTForNonEmptyContent();\n";
	out << "			}\n";
	out << "			else\n";
	out << "			{\n";
	out << "				// minor optimisation to avoid allocation on empty contents\n";
	out << "				rootnode = new Node();\n";
	out << "				rootnode->rule = rgUnknown;\n";
	out << "				rootnode->offset = 0;\n";
	out << "				rootnode->offsetEnd = 0;\n";
	out << "			}\n";
	out << "		}\n";
	out << "		else\n";
	out << "			rootnode = nullptr;\n";
	out << '\n';
	out << "		# if HAS_STATISTICS != 0 && !defined(NDEBUG)\n";
	out << "		{\n";
	out << "			uint realRuleCount = 0;\n";
	out << '\n';
	out << "			for (uint i = 0; i != offset; ++i)\n";
	out << "			{\n";
	out << "				if (stack[i].rule > 0)\n";
	out << "					++realRuleCount;\n";
	out << "			}\n";
	out << '\n';
	out << "			TRACE_INFO(\"STATISTICS\");\n";
	out << "			TRACE_INFO(\"result: \" << (success ? \"OK\" : \"FAILED\") << \"  (\" << duration << \"ms)\");\n";
	out << "			uint ratio = (uint)((double) realRuleCount * 100. / offset);\n";
	out << "			TRACE_INFO(\"stack: \" << realRuleCount << \" rules for \" << offset << \" stack frames, ratio: \" << ratio << \"% (higher is better), max depth: \" << maxOffset);\n";
	out << "			TRACE_INFO(\"stack: \" << ((capacity * sizeof(Chunk)) / 1024) << \" KiB (capacity: \" << capacity << \", \" << sizeof(Chunk) << \" bytes per frame)\");\n";
	out << "			uint64 totalCapa = 0;\n";
	out << "			for (uint i = 0; i != (uint) contents.size(); ++i)\n";
	out << "				totalCapa += contents[i].capacity();\n";
	out << "			TRACE_INFO(\"content from urls: \" << contents.size() << \", total \" << (totalCapa / 1024) << \" KiB in memory\");\n";
	out << '\n';
	out << "			totalCapa += (capacity * sizeof(Chunk));\n";
	out << "			for (uint i = 0; i != (uint) urls.size(); ++i)\n";
	out << "				totalCapa += urls[i].capacity();\n";
	out << "			totalCapa += root.capacity();\n";
	out << "			TRACE_INFO(\"total memory usage: \" << (totalCapa / 1024) << \" KiB\");\n";
	out << "		}\n";
	out << "		# endif\n";
	out << '\n';
	out << "		// cleanup\n";
	out << "		::free(stack);\n";
	out << "		stack = nullptr;\n";
	out << "		offset = 0;\n";
	out << "		capacity = 0;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	void Datasource::buildASTForNonEmptyContent()\n";
	out << "	{\n";
	out << "		// at this point, the parse was successful and something has been found\n";
	out << "		assert(success);\n";
	out << "		assert(offset > 0);\n";
	out << "		assert(stack[0].rule == + (int) rgEOF and \"invalid stack (should have called isParseComplete())\");\n";
	out << '\n';
	out << "		// all AST nodes, mapping the stack elements\n";
	out << "		Node::Vector astNodes;\n";
	out << "		astNodes.resize(offset + 1);\n";
	out << '\n';
	out << "		// pseudo root node to avoid special cases for retrieving the parent node\n";
	out << "		astNodes[0] = new Node();\n";
	out << "		astNodes[0]->rule = rgUnknown;\n";
	out << "		astNodes[0]->offset = 0;\n";
	out << "		astNodes[0]->offsetEnd = 0;\n";
	out << "		Node& pseudoRootNode = *astNodes[0];\n";
	out << '\n';
	out << "		// starting from the first real frame\n";
	out << "		for (uint i = 1; i != offset; ++i)\n";
	out << "		{\n";
	out << "			const Chunk& cursor = stack[i];\n";
	out << '\n';
	out << "			# ifndef NDEBUG\n";
	out << "			if (cursor.rule < 0)\n";
	out << "			{\n";
	out << "				std::cerr << \"assert failed: invalid rule  \";\n";
	out << "				PrintFrame(std::cerr, cursor) << std::endl;\n";
	out << "				assert(cursor.rule >= 0 and \"some rules are not commited - the parse should have failed\");\n";
	out << "			}\n";
	out << "			# endif\n";
	out << '\n';
	out << "			if (cursor.rule <= 0)\n";
	out << "				continue;\n";
	out << '\n';
	out << "			# ifndef NDEBUG\n";
	out << "			if (not (cursor.parent < offset))\n";
	out << "			{\n";
	out << "				std::cerr << \"assert failed: invalid parent: \" << i << \"/\" << offset << \",  \";\n";
	out << "				PrintFrame(std::cerr, cursor) << std::endl;\n";
	out << "				assert(cursor.parent < offset and \"invalid parent index\");\n";
	out << "			}\n";
	out << "			assert(cursor.parent < astNodes.size());\n";
	out << "			assert(!(!astNodes[cursor.parent]) and \"invalid parent\");\n";
	out << "			# endif\n";
	out << '\n';
	out << "			// The grammar rule for the current node\n";
	out << "			enum Rule rule = (enum Rule) cursor.rule;\n";
	out << '\n';
	out << "			assert(cursor.parent < astNodes.size());\n";
	out << "			assert((uint64) i < astNodes.size());\n";
	out << '\n';
	out << "			Node::Ptr newnode = new Node();\n";
	out << "			astNodes[i] = newnode;\n";
	out << "			astNodes[cursor.parent]->children.push_back(newnode);\n";
	out << '\n';
	out << "			newnode->rule      = rule;\n";
	out << "			newnode->offset    = cursor.offset;\n";
	out << "			newnode->offsetEnd = cursor.offsetEnd;\n";
	out << '\n';
	out << "			// Flag to determine whether the node has to capture the content or not\n";
	out << "			bool attrCapture = RuleAttributeCapture(rule);\n";
	out << "			if (attrCapture)\n";
	out << "			{\n";
	out << "				// Checking integrity of the captured content\n";
	out << "				assert(\n";
	out << "					cursor.offsetEnd >= cursor.offset                // valid end offset\n";
	out << "					and cursor.offsetEnd != (uint) -1                // valid end offset\n";
	out << "					and cursor.offset    != (uint) -1                // valid offset\n";
	out << "					and cursor.urlindex  <  (uint)contents.size()    // valuid url index\n";
	out << "					and cursor.offset    <  contents[cursor.urlindex].size()  // valid range\n";
	out << "					and cursor.offsetEnd <= contents[cursor.urlindex].size() // valid range\n";
	out << "					and \"invalid offset for content capture\");\n";
	out << '\n';
	out << "				// size of the captured content\n";
	out << "				uint size = cursor.offsetEnd - cursor.offset;\n";
	out << "				// Captured content\n";
	out << "				newnode->text.assign(contents[cursor.urlindex], size, cursor.offset);\n";
	out << "			}\n";
	out << "		}\n";
	out << '\n';
	out << "		rootnode = (pseudoRootNode.children.size() == 1)\n";
	out << "			? pseudoRootNode.children[0]\n";
	out << "			: nullptr;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	void Datasource::notify(const AnyString& message) const\n";
	out << "	{\n";
	out << "		Chunk& cursor    = stack[offset];\n";
	out << "		const Clob& data = contents[cursor.urlindex];\n";
	out << '\n';
	out << "		uint line = 1;\n";
	out << "		uint x = 0;\n";
	out << '\n';
	out << "		// trying to find the appropriate line index\n";
	out << "		if (cursor.offset < data.size())\n";
	out << "		{\n";
	out << "			for (uint i = 0; i != cursor.offset; ++i)\n";
	out << "			{\n";
	out << "				if (data[i] == '\\n')\n";
	out << "				{\n";
	out << "					++line;\n";
	out << "					x = 0;\n";
	out << "				}\n";
	out << "				else\n";
	out << "					++x;\n";
	out << "			}\n";
	out << "		}\n";
	out << '\n';
	out << "		Notification* notification = new Notification();\n";
	out << "		notification->offset     = ((0 != x) ? x : 1);\n";
	out << "		notification->line       = line;\n";
	out << "		notification->message    = message;\n";
	out << "		notification->filename   = urls[cursor.urlindex];\n";
	out << '\n';
	out << "		const_cast<Notification::Vector&>(notifications).push_back(notification);\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline bool Datasource::isParseComplete() const\n";
	out << "	{\n";
	out << "		if (offset > 1)\n";
	out << "		{\n";
	out << "			assert(offset < capacity);\n";
	out << "			assert(stack[offset].urlindex < (uint) urls.size());\n";
	out << "			assert(stack[0].rule == - (int) rgEOF and \"invalid stack\");\n";
	out << '\n';
	out << "			// pseudo commit the root frame\n";
	out << "			stack[0].rule = + (int) rgEOF;\n";
	out << '\n';
	out << "			// trying to find the commit rule \"start\", which should be at index 1\n";
	out << "			uint startoffset = 1;\n";
	out << "			do\n";
	out << "			{\n";
	out << "				if (stack[startoffset].rule == rgStart)\n";
	out << "				{\n";
	out << "					Chunk& cursor = stack[startoffset];\n";
	out << '\n';
	out << "					if (cursor.urlindex == 0) // the original input source\n";
	out << "					{\n";
	out << "						// the original content\n";
	out << "						const Clob& data = contents[cursor.urlindex];\n";
	out << '\n';
	out << "						if (cursor.offset < data.size() and cursor.offsetEnd <= data.size())\n";
	out << "						{\n";
	out << "							if (data.size() == cursor.offsetEnd)\n";
	out << "								return true;\n";
	out << "						}\n";
	out << "					}\n";
	out << '\n';
	out << "					break;\n";
	out << "				}\n";
	out << '\n';
	out << "				++startoffset;\n";
	out << "			}\n";
	out << "			while (startoffset <= offset);\n";
	out << '\n';
	out << "			notify(\"failed to parse\");\n";
	out << "		}\n";
	out << '\n';
	out << "		return false;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << "	inline void Datasource::translateOffset(uint& column, uint& line, uint offset) const\n";
	out << "	{\n";
	out << "		uint fileindex = 0;\n";
	out << '\n';
	out << "		if (fileindex < (uint) contents.size())\n";
	out << "		{\n";
	out << "			// alias to the content\n";
	out << "			const Clob& content = contents[fileindex];\n";
	out << "			// maximum size\n";
	out << "			uint maxSize = std::max((uint) content.size(), offset);\n";
	out << '\n';
	out << "			for (uint x = 0; x != maxSize; ++x)\n";
	out << "			{\n";
	out << "				if (content[x] == '\\n')\n";
	out << "				{\n";
	out << "					column = 0;\n";
	out << "					++line;\n";
	out << "				}\n";
	out << "				else\n";
	out << "					++column;\n";
	out << "			}\n";
	out << "		}\n";
	out << '\n';
	out << "		if (line != 0 and column == 0)\n";
	out << "			column = 1;\n";
	out << "	}\n";
	out << '\n';
	out << '\n';
	out << '\n';
	out << '\n';
	out << "";
}
